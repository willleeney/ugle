seeds: [42, 24, 976, 12345, 98765, 7, 856, 90, 672, 785]
datasets: ['cora', 'citeseer', 'texas', 'dblp', 'vgaer']
algorithms: ['sublime', 'bgrl', 'vgaer', 'daegc', 'dmon', 'grace']
dataset_algo_combinations: null
run_cpu_fallback: False
special_training: 
  split_addition_percentage: False
  retrain_on_each_dataset: False

study_override_cfg:
  trainer:
    n_trials_hyperopt: 250
    results_path: './results/hpo_q2_sup/'

    show_config: False
    load_existing_test: False
    calc_time: False

    test_metrics: ['f1', 'nmi', 'modularity', 'conductance']
    valid_metrics: ['f1', 'nmi', 'modularity', 'conductance']
    gpu: '3'
    split_scheme: 'drop_edges'
    train_to_valid_split: 1.0
    training_to_testing_split: 1.0
